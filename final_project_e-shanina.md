# Финальный проект. Вариант 1. Шанина Екатерина, 07.10, e-shanina

* *В данном файле представлено описание подходов и интерпретация результатов. Код смотреть в файле* *
* *"final_project_e-shanina_python.ipynb"* *

## Задание 1. Написать функцию для расчета retention. 

Классический **Day N Retention** показывает, какой процент новых пользователей вернулись в продукт в конкретный день с момента прихода. Оно считается с помощью деления количества пользователей, которые открывают приложение в n-ный день после его первого открытия (day 0) на количество пользователей, которые впервые использовали приложение в первый день (day 0).

При написании формулы retention должны быть пройдены следующие **этапы**:
1. Чтение базы данных с информацией о посещениях приложения и датах регистрации пользователей;
2. Преобразование даты формата кол-ва секунд в формат даты, детализация до дней, так как нас интересуют дневные показатели. 
3. Соединение двух баз данных (базы с датами регистраций и базы с датами захода пользователей в игру). Так как первая дата захода в игру = дата регистрации, в базе с регистрациями есть все пользователи, которые есть в базе с посещениями, необходимо к базе по посещениям соединить базу с регистрациями, чтобы не потерять данные о более чем одном посещении игры пользователем. 
4. Расчет показателя, который указывает, на какой день после регистрации пользователь посетил игру. Существует два способа рассчитать день, прошедший с момента регистрации: календарный (при наступлении новых календарных суток считаем, что прошел день) и 24-часовой (день – период из 24 часов, при прошествии 24 часов проходит 1 день). В данном задании требуется retention по дням от даты регистрации игрока. 
5. Предыдущие этапы были подготовительными. Финальный этап – сама формула, которая считает процент пользователей, вернувшийся в приложение на n-ный день после регистрации. 

**Основные выдержки из кода:**

    <# Импорт пакетов, которые будут нужны при написании формулы

    import pandas as pd
    import datetime
    import math
    
    # Формула n-day retention
    def retention_rate(n):
        reg_data = pd.read_csv('/mnt/HC_Volume_18315164/home-jupyter/jupyter-e-shanina/shared/problem1-reg_data.csv', sep=';')
        auth_data = pd.read_csv('/mnt/HC_Volume_18315164/home-jupyter/jupyter-e-shanina/shared/problem1-auth_data.csv', sep=';')
        reg_data['reg_day'] = pd.to_datetime(reg_data.reg_ts, unit = 's').astype('datetime64[D]')
        auth_data['auth_day'] = pd.to_datetime(auth_data.auth_ts, unit = 's').astype('datetime64[D]')
        all_data = auth_data.merge(reg_data, how = 'left', on='uid')
        all_data['days_from_reg'] = all_data.auth_day - all_data.reg_day
        query_number_of_days = f"days_from_reg == '{n} days'"
        return all_data.groupby(['uid', 'auth_day', 'reg_day', 'days_from_reg'], as_index=False) \
                       .agg({'auth_ts': 'count'}) \
                       .query(query_number_of_days) \
                       .days_from_reg.count()/all_data.uid.nunique()>
                       
                       
## Задание 2. Какой набор предложений можно считать лучшим? Какие метрики стоит проанализировать для принятия правильного решения и как?

Чтобы понять, какой набор предложений является лучшим, необходимо знать, какой критерий успешности мы применяем. Предположим, что **целью** составления тестового набора акционных предложений является **увеличение ARPU**.  То есть **лучшее предложение – то, которое приносит нам более высокую среднюю выручку с пользователя.**

Мы видим, что ARPU тестовой выборки больше на 5%, чем ARPU контрольной выборки. Необходимо провести тестирование, чтобы понять, являются ли изменения средней выручки в тестовой группе случайными или нет. Так как **наша задача – проверить нулевую гипотезу о том, что значимые отличия между средней выручкой в тестовой и контрольной выборке отсутствуют**, для проверки гипотезы используем **метод Bootstrap**. Данный метод заключается в применении следующих шагов: 
1. Из каждой выборки, контрольной и тестовой, составляем подвыборку с повторениями (то есть выручка одного клиента может быть выбрана в выборку несколько раз).
2. Для каждой подвыборки считаем среднее и сравниваем средние тестовой и контрольной подвыборок. 
3. Процедура повторяется 1000 раз. Взято достаточно большое число итераций, так как это позволит провести более точный анализ. 
4. Строим распределение разностей средних в контрольной и тестовой выборке и смотрим, какие значения разности попадают в 95% доверительный интервал. Если в данный интервал попал 0, это значит, что значимых различий нет, если 0 не попал, значит разница между средними неслучайна. 

Применение метода Bootstrap в Python отражено в файле “final_project_e-shanina_python.ipynb”.

**Результаты** Bootstrap среднего всей выборки говорят о том, что **нет значимых различий между средней выручкой в тестовой и контрольной выборках, то есть мы не можем сказать, что какой-то из наборов лучше, чем другой**. Этот вывод логичен, так как покупающая аудитория составляет лишь менее 1% от всех пользователей, и изменение наборов акционных предложений также влияет не на всю аудиторию, так как большинство не совершает покупки совсем. 

Поэтому **вторым шагом проверим, какие изменения в средней и медианной выручке произошли только среди покупающей аудитории** в несколько шагов:
1. Оставим данные только по тем пользователям, выручка которых > больше 0. 
2. Посчитаем описательные статистики только для платящих пользователей. Видим, что произошел рост средней, медианной и общей выручки в тестовой группе по сравнению с контрольной группой.
3. Для выяснения, значимы ли различия в средней выручке используем метод Bootstrap. В качестве проверяемой статистики берем медиану, так как она менее подвержена влиянию выбросов, чем среднее. А по распределению выручки в контрольной группе мы видим, что выбросы есть.

Применение Bootstrap медианы показывает, что **различия в средней выручке между экспериментальными группами не являются случайными**. Доверительный интервал не содержит 0, это значит, что мы отклоняем нулевую гипотезу, различия между медианной выручкой пользователя в тестовой и контрольной группах значимы, в тестовой группе медианная выручка больше.   

Стоит также обратить внимание на группу пользователей, которые совершают очень крупные покупки (свыше 35 000). Если это реальные пользователи, а не сбой системы, то следует отдельно рассмотреть набор акционных предложений для данных пользователей. Их наличие выгодно для компании, так как приносит крупные суммы денег, а тестовые наборы, видимо, не включают в себя возможность оплаты пакета на крупную сумму, что странно с точки зрения получения дохода. Если это сбой, и данные пользователи на самом деле не совершали покупку или совершали покупку на небольшие чеки, то еще более явно превосходство тестового набора по ARPU. 

**Выводы:** 
1. Изменение набора акционных предложений не имеет значимого влияния на среднюю выручку с пользователя мобильной игры в целом. Это может быть связано с тем, что доля пользователей, совершающих покупки, очень мала. 
2. Если рассматривать только пользователей, совершивших покупки, то средняя, медианная и общая выручка также больше в тестовой группе. Причем различия медианы являются значимыми, то есть средняя выручка в тестовой группе значимо выше, чем в контрольной. Таким образом, если делать вывод на основе анализа только платящей аудитории, **тестовый набор можно считать лучшим**. 
3. Следует обратить внимание на подгруппу пользователей, которые платят более 35 000. Если эти выбросы – не результат сбоя, а реальные покупки пользователей, тестовый набор акций, по-видимому, не включает в себя предложение для пользователей с таким спросом, возможно, будет разумным его разработать. 



## Задание 3. Предложите метрики для оценки результатов последнего прошедшего тематического события в игре.

### В игре Plants & Gardens каждый месяц проводятся тематические события, ограниченные по времени. В них игроки могут получить уникальные предметы для сада и персонажей, дополнительные монеты или бонусы. Для получения награды требуется пройти ряд уровней за определенное время. С помощью каких метрик можно оценить результаты последнего прошедшего события?

1. **Average Session Duration**. Это среднее время сессий за период времени проведения тематического события. ASD = Суммарная продолжительность сессий за период / общее количество сессий за тот же период. Предположительно, наличие бонусов, уникальных предметов должно привести к увеличению длины сессии. 

2. **Игровое время на одного пользователя в день** (Average Playing Time Per Day) в дни игрового события. Данный показатель характеризует вовлеченность пользователя в игру и интересен с точки зрения повышения доходов, так как чем больше времени пользователь проводит в игре, тем больше шанс, что он что-либо приобретет. 

3. **Stickness rate** за время проведения тематического события. Этот показатель рассчитывается как DAU/EAU (Event active users, кол-во активных пользователей игры во время события) и характеризует лояльность аудитории к событию. Если данный показатель равен 100%, значит все пользователи ежедневно заходят игру. Предположительно, появление тематического события в игре, должно стимулировать пользователей заходить чаще, Stickness rate во время события ожидается выше, чем при стандартном ходе игры без событий. 

4. **LTV** за время события (Lifetime value) – суммарный доход, полученный с пользователей, которые зарегистрировались на событие, за время его проведения. Предположительно, тематическое событие поднимет вовлеченность пользователей, что приведет к получению большего дохода. 

### Предположим, в другом событии мы усложнили механику событий так, что при каждой неудачной попытке выполнения уровня игрок будет откатываться на несколько уровней назад. Изменится ли набор метрик оценки результата? Если да, то как?

Метриками, описанными выше также можно оценить результат при изменении механики. Однако, также к ним нужно добавить:

1. **Среднее количество попыток пройти уровни после отката**. Если это число маленькое, значит новая механика не мотивирует пользователей продолжать играть даже после неудачи в прохождении уровня, если число высокое, то пользователи заинтересованы и вовлечены в игру. Также низкие значения показателя могут указать, на то, что существуют уровни, достижение которых слишком сложно для пользователей, и необходимо пересмотреть их сложность. 

2. **Churn rate** – отток пользователей. Так как изменения повлияли на механику игры, необходимо отследить, не привели ли эти изменения к изменению churn rate. Отток пользователей возможен, если уровни слишком сложны для прохождения и пользователи вынуждены проходить один и тот же набор уровней (в связи с тем, что в игре действуют откаты на несколько уровней назад), что негативно влияет на мотивацию к прохождению.  



    
    
    
    

                       
                       
                    

